geom_jitter(position=position_jitter(0.2),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.1, aes(color=Station)) +
geom_jitter(position=position_jitter(0.2),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5) +
geom_jitter(position=position_jitter(0.2),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5, alpha=0.8) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5, alpha=0.5) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5, alpha=0.5) +
stat_summary(fun.y=mean, geom="point", shape=5, size=4) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5, alpha=0.5) +
stat_summary(fun.y=mean, geom="point", shape=2, size=2) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_boxplot(width=0.5, alpha=0.5) +
stat_summary(fun.y=mean, geom="point", shape=2, size=2) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
#geom_boxplot(width=0.5, alpha=0.5) +
stat_summary(fun.y=mean, geom="point", shape=2, size=2) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
# Plot a violin plot to show distribution
ggplot(df, aes(x=Station, y=Flow)) +
geom_violin(trim = FALSE) +
ggtitle("Violin plot of flow distribution at 10 sample stations") +
geom_boxplot(width=0.05) +
stat_summary(fun.y=mean, geom="point", shape=2, size=2) +
#coord_flip() +
theme_minimal()
# Plot a violin plot to show distribution
ggplot(df, aes(x=Station, y=Flow)) +
geom_violin(trim = FALSE) +
ggtitle("Violin plot of flow distribution at 10 sample stations") +
geom_boxplot(width=0.05) +
stat_summary(fun.y=mean, geom="point", shape=1, size=1) +
#coord_flip() +
theme_minimal()
# Plot a violin plot to show distribution
ggplot(df, aes(x=Station, y=Flow)) +
geom_violin(trim = FALSE) +
ggtitle("Violin plot of flow distribution at 10 sample stations") +
geom_boxplot(width=0.05) +
theme_minimal()
# Plot a jitter plot
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
stat_summary(fun.y=mean, geom="point", shape=2, size=2) +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
# Plot a jitter plot
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
stat_summary(fun.y=median, geom="point", shape=2, size=2) +
theme(legend.position = "none") +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station)) +
stat_summary(fun.y=median, geom="point", shape=2, size=2)
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
# Plot a violin plot to show distribution
ggplot(df, aes(x=Station, y=Flow)) +
geom_violin(trim = FALSE) +
ggtitle("Violin plot of flow distribution at 10 sample stations") +
geom_boxplot(width=0.05) +
theme_minimal()
# Plot a jitter plot
ggplot(df, aes(x=Station, y=Flow)) +
ggtitle("Jitter strip plot of flow distribution at 10 random stations") +
theme_minimal() +
theme(legend.position = "none") +
geom_jitter(position=position_jitter(0.1),alpha=0.2, aes(color=Station))
library(tidyverse)
library(dplyr)
library(lubridate)
data <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
deathData <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
select(UID, Lat, Long_) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
df <- df %>% left_join(death, by=c("UID", "date")) %>%
rename('case' = `count.x`, "death" = `count.y`)
## Group by week/day etc
# df <- group_by(df, UID, date=cut(date, "1 week")) %>%
#   summarise(case = sum(case), death=sum(death), lat=first(lat), lon=first(lon))  %>%
#   arrange(UID, date)
# add cumsum
df <- mutate(group_by(df,UID), case_cum=cumsum(case), death_cum=cumsum(death))
### Areas with case_cumsum > 1000
filtered <- df %>%
group_by(UID) %>%
summarize(max = max(case_cum)) %>%
filter(max > 500)
df <- filter(df, UID %in% filtered$UID)
# Add growth factor
df <- df %>%
arrange(UID, date) %>%
mutate(case_gf=case/lag(case), death_gf=death/lag(death))
formatGrowthFactors <- function(df, colName) {
COL <- pull(df, colName)
COL <- COL %>% replace_na(0) %>% round(3) # Change N/A to 0, this is when it is 0 after 0
COL[is.infinite(COL)] <- 1 # Change infinite to 1, this when it goes up from 0 so percentge is undefined
df[[colName]] <- COL
return(df)
}
df <- formatGrowthFactors(df, "case_gf")
df <- formatGrowthFactors(df, "death_gf")
### After March
df <- filter(df, date > "2020-03-01")
df <- arrange(df, date)
totals <- group_by(df, date) %>% summarize(case=sum(case), death=sum(death), case_cum=cumsum(case), death_cum=cumsum(death))
write_csv(lookup, 'lookup.csv')
write_csv(df, 'geo_cleaned.csv')
write_csv(totals, 'totals.csv')
#View(df)
View(data)
View(lookup)
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
View(lookup)
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
library(tidyverse)
library(dplyr)
library(lubridate)
data <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
deathData <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
df <- df %>% left_join(death, by=c("UID", "date")) %>%
rename('case' = `count.x`, "death" = `count.y`)
## Group by week/day etc
# df <- group_by(df, UID, date=cut(date, "1 week")) %>%
#   summarise(case = sum(case), death=sum(death), lat=first(lat), lon=first(lon))  %>%
#   arrange(UID, date)
# add cumsum
df <- mutate(group_by(df,UID), case_cum=cumsum(case), death_cum=cumsum(death))
### Areas with case_cumsum > 1000
filtered <- df %>%
group_by(UID) %>%
summarize(max = max(case_cum)) %>%
filter(max > 500)
df <- filter(df, UID %in% filtered$UID)
# Add growth factor
df <- df %>%
arrange(UID, date) %>%
mutate(case_gf=case/lag(case), death_gf=death/lag(death))
formatGrowthFactors <- function(df, colName) {
COL <- pull(df, colName)
COL <- COL %>% replace_na(0) %>% round(3) # Change N/A to 0, this is when it is 0 after 0
COL[is.infinite(COL)] <- 1 # Change infinite to 1, this when it goes up from 0 so percentge is undefined
df[[colName]] <- COL
return(df)
}
df <- formatGrowthFactors(df, "case_gf")
df <- formatGrowthFactors(df, "death_gf")
### After March
df <- filter(df, date > "2020-03-01")
df <- arrange(df, date)
totals <- group_by(df, date) %>% summarize(case=sum(case), death=sum(death), case_cum=cumsum(case), death_cum=cumsum(death))
write_csv(lookup, 'lookup.csv')
write_csv(df, 'geo_cleaned.csv')
write_csv(totals, 'totals.csv')
#View(df)
setwd("~/Documents/UCF/Study/Semester 2/CAP 6737 - Data Visualization/Group Project.tmp")
library(tidyverse)
library(dplyr)
library(lubridate)
data <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
deathData <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
df <- df %>% left_join(death, by=c("UID", "date")) %>%
rename('case' = `count.x`, "death" = `count.y`)
## Group by week/day etc
# df <- group_by(df, UID, date=cut(date, "1 week")) %>%
#   summarise(case = sum(case), death=sum(death), lat=first(lat), lon=first(lon))  %>%
#   arrange(UID, date)
# add cumsum
df <- mutate(group_by(df,UID), case_cum=cumsum(case), death_cum=cumsum(death))
### Areas with case_cumsum > 1000
filtered <- df %>%
group_by(UID) %>%
summarize(max = max(case_cum)) %>%
filter(max > 500)
df <- filter(df, UID %in% filtered$UID)
# Add growth factor
df <- df %>%
arrange(UID, date) %>%
mutate(case_gf=case/lag(case), death_gf=death/lag(death))
formatGrowthFactors <- function(df, colName) {
COL <- pull(df, colName)
COL <- COL %>% replace_na(0) %>% round(3) # Change N/A to 0, this is when it is 0 after 0
COL[is.infinite(COL)] <- 1 # Change infinite to 1, this when it goes up from 0 so percentge is undefined
df[[colName]] <- COL
return(df)
}
df <- formatGrowthFactors(df, "case_gf")
df <- formatGrowthFactors(df, "death_gf")
### After March
df <- filter(df, date > "2020-03-01")
df <- arrange(df, date)
totals <- group_by(df, date) %>% summarize(case=sum(case), death=sum(death), case_cum=cumsum(case), death_cum=cumsum(death))
write_csv(lookup, 'lookup.csv')
write_csv(df, 'geo_cleaned.csv')
write_csv(totals, 'totals.csv')
#View(df)
setwd("~/Documents/UCF/Study/Semester 2/CAP 6737 - Data Visualization/Group Project.tmp")
library(tidyverse)
library(dplyr)
library(lubridate)
data <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
deathData <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
df <- df %>% left_join(death, by=c("UID", "date")) %>%
rename('case' = `count.x`, "death" = `count.y`)
## Group by week/day etc
# df <- group_by(df, UID, date=cut(date, "1 week")) %>%
#   summarise(case = sum(case), death=sum(death), lat=first(lat), lon=first(lon))  %>%
#   arrange(UID, date)
# add cumsum
df <- mutate(group_by(df,UID), case_cum=cumsum(case), death_cum=cumsum(death))
### Areas with case_cumsum > 1000
# filtered <- df %>%
#   group_by(UID) %>%
#   summarize(max = max(case_cum)) %>%
#   filter(max > 500)
df <- filter(df, UID %in% filtered$UID)
# Add growth factor
df <- df %>%
arrange(UID, date) %>%
mutate(case_gf=case/lag(case), death_gf=death/lag(death))
formatGrowthFactors <- function(df, colName) {
COL <- pull(df, colName)
COL <- COL %>% replace_na(0) %>% round(3) # Change N/A to 0, this is when it is 0 after 0
COL[is.infinite(COL)] <- 1 # Change infinite to 1, this when it goes up from 0 so percentge is undefined
df[[colName]] <- COL
return(df)
}
df <- formatGrowthFactors(df, "case_gf")
df <- formatGrowthFactors(df, "death_gf")
### After March
df <- filter(df, date > "2020-03-01")
df <- arrange(df, date)
totals <- group_by(df, date) %>% summarize(case=sum(case), death=sum(death), case_cum=cumsum(case), death_cum=cumsum(death))
write_csv(lookup, 'lookup.csv')
write_csv(df, 'geo_cleaned.csv')
write_csv(totals, 'totals.csv')
#View(df)
View(lookup)
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
lookup <- lookup %>%
filter(!is.na(FIPS), code3 == 840) %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
write_csv(lookup, 'lookup.csv')
library(tidyverse)
library(dplyr)
library(lubridate)
data <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
deathData <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
filter(!is.na(FIPS), code3 == 840) %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
df <- df %>% left_join(death, by=c("UID", "date")) %>%
rename('case' = `count.x`, "death" = `count.y`)
## Group by week/day etc
# df <- group_by(df, UID, date=cut(date, "1 week")) %>%
#   summarise(case = sum(case), death=sum(death), lat=first(lat), lon=first(lon))  %>%
#   arrange(UID, date)
# add cumsum
df <- mutate(group_by(df,UID), case_cum=cumsum(case), death_cum=cumsum(death))
### Areas with case_cumsum > 1000
# filtered <- df %>%
#   group_by(UID) %>%
#   summarize(max = max(case_cum)) %>%
#   filter(max > 500)
df <- filter(df, UID %in% filtered$UID)
# Add growth factor
df <- df %>%
arrange(UID, date) %>%
mutate(case_gf=case/lag(case), death_gf=death/lag(death))
formatGrowthFactors <- function(df, colName) {
COL <- pull(df, colName)
COL <- COL %>% replace_na(0) %>% round(3) # Change N/A to 0, this is when it is 0 after 0
COL[is.infinite(COL)] <- 1 # Change infinite to 1, this when it goes up from 0 so percentge is undefined
df[[colName]] <- COL
return(df)
}
df <- formatGrowthFactors(df, "case_gf")
df <- formatGrowthFactors(df, "death_gf")
### After March
#df <- filter(df, date > "2020-03-01")
df <- arrange(df, date)
totals <- group_by(df, date) %>% summarize(case=sum(case), death=sum(death), case_cum=cumsum(case), death_cum=cumsum(death))
write_csv(lookup, 'lookup.csv')
write_csv(df, 'geo_cleaned.csv')
write_csv(totals, 'totals.csv')
#View(df)
View(df)
group_by(date, df)
group_by(df, date)
group_by(df, date) %>% summarize(n=n())
group_by(df, date, UID) %>% summarize(n=n())
group_by(df, date) %>% summarize(n=n())
group_by(df, date) %>% summarize(n=n()) %>% tail(20)
unique(df$UID)
length(unique(df$UID))
length(unique(data$UID))
library(tidyverse)
library(dplyr)
library(lubridate)
data <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
deathData <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")
lookup <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
reformatData <- function(data) {
return(
data %>%
gather("date", "count",  names(data)[grepl("X", names(data))]) %>%
filter(iso2 == "US", Lat != "0", Long_ != "0") %>% #Only include US and with lat long values
#select(c(UID, FIPS, Admin2, Province_State ,Lat, Long_, date, count)) %>%
select(UID, date, count) %>% # Select required
mutate(date = str_replace_all(date, "X", "")) %>% # Fix date
mutate(date = as.Date(date, format = "%m.%d.%y")) %>% # Parse date
arrange(date) # sort by date
)
}
df <- reformatData(data)
death <- reformatData(deathData)
lookup <- lookup %>%
filter(!is.na(FIPS), code3 == 840) %>%
select(UID, Lat, Long_, FIPS) %>% # Select any attributes needed from lookup
rename('lat' = Lat, 'lon' = Long_) # Rename for ease
df <- df %>% left_join(death, by=c("UID", "date")) %>%
rename('case' = `count.x`, "death" = `count.y`)
## Group by week/day etc
# df <- group_by(df, UID, date=cut(date, "1 week")) %>%
#   summarise(case = sum(case), death=sum(death), lat=first(lat), lon=first(lon))  %>%
#   arrange(UID, date)
# add cumsum
df <- mutate(group_by(df,UID), case_cum=cumsum(case), death_cum=cumsum(death))
### Areas with case_cumsum > 1000
# filtered <- df %>%
#   group_by(UID) %>%
#   summarize(max = max(case_cum)) %>%
#   filter(max > 500)
#df <- filter(df, UID %in% filtered$UID)
# Add growth factor
df <- df %>%
arrange(UID, date) %>%
mutate(case_gf=case/lag(case), death_gf=death/lag(death))
formatGrowthFactors <- function(df, colName) {
COL <- pull(df, colName)
COL <- COL %>% replace_na(0) %>% round(3) # Change N/A to 0, this is when it is 0 after 0
COL[is.infinite(COL)] <- 1 # Change infinite to 1, this when it goes up from 0 so percentge is undefined
df[[colName]] <- COL
return(df)
}
df <- formatGrowthFactors(df, "case_gf")
df <- formatGrowthFactors(df, "death_gf")
### After March
#df <- filter(df, date > "2020-03-01")
df <- arrange(df, date)
totals <- group_by(df, date) %>% summarize(case=sum(case), death=sum(death), case_cum=cumsum(case), death_cum=cumsum(death))
write_csv(lookup, 'lookup.csv')
write_csv(df, 'geo_cleaned.csv')
write_csv(totals, 'totals.csv')
#View(df)
length(unique(df$UID))
group_by(df, date) %>% summarize(n=n()) %>% tail(20)
View(data)
